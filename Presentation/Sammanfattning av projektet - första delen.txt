Kunskapskontroll 2: MNIST-modellering med tillhörande Streamlit-app
Michael Broström

Det här har varit ett mycket lärorikt och intressant projekt. Det har tagit många och långa timmar, 
men har hela tiden varit väldigt roligt. Utom när man suttit och väntat på modellens träning. 


Struktur
Hela projektet är nu uppbyggt som en komplett pipeline för maskininlärning, från inläsning av rådata till logisk verifiering och en användardriven förbättring som kan leva vidare och bidra till en bättre och bättre modell.

Modellering
Efter att ha funderat lite på hur jag skulle komma igång så tänkte jag att det bästa måste vara att bygga en stabil bas genom att fokusera på grundflödet i maskininlärning. 

Jag tittade igenom föreläsningarna igen och lät bokens arbetsgång vara stommen för min egen hantering i början. Bokens Extra Trees hade räckt, men efter lite experimenterande blev valet en standard-SVC-modell (Support Vector Classifier) och eftersom jag hade "tjuvstartat" så blev den utan någon dimensionsreducering (som vi då inte hade gått igenom än). 

För bästa möjliga datahantering normaliserade jag alla pixlar (784 features) genom att helt sonika dela dem med 255.0, vilket undanröjde behovet av StandardScaler.

Efter en hel del experimenterande och "skruvande på alla rattar" blev resultatet en färdig produktionsmodell med en accuracy på 0.9834. Det fick räknas som godkänt och jag gick därför vidare till preprocessing och prediktion. 

Fortsatt modellering
När appen var klar gick jag dock tillbaka för att jaga bättre siffror. En Accuracy på 99% borde inte vara omöjlig även utan neuralt nätverk. 

Från den stabila baslinje jag hade i min första "färdiga" modellering, en SVC med en accuracy på 0.9834 fick jag förnyad motivation när mina kamrater fick värden upppåt 0.985 och högre. Jag satte därför på mig tänkarhatten och körde vidare. 

1. Jag hade inte tidigare använt PCA så det var första steget. Jag experimenterade också med standardscaler, men återgick ganska snart till mitt "trick" att normalisera data genom att dela dem med 255.0 - det bevarar "tystnaden" i bakgrunden och var gynnsamt för dimensionsreduceringen. 

2. De 70 000 MNIST-bilderna delades 80/20 med stratifiering för att bibehålla samma klassfördelning i alla steg.

3. Jag experimenterade mycket med olika modeller, med voting och allsköns alternativ, men det visade sig hela tiden att SVC med rbf-kärna var den starkaste modellen. Med hjälp av dimensionsreducering (PCA) hanterade jag det som i boken och på en föreläsning kallades "the curse of dimensionality". Diverse analyser pekade på en kraftig reducering av dimensioner och efter diverse bildbehandling och handpåläggning visade det sig att 112 komponenter var "sweetspot". 

4. Därefter skapades en pipeline-arkitektur som mall, eller "single source of truth", för att säkerställa att testdata skulle transformeras exakt likadant som träningsdata.

5. SVC med PCA var bra och gav fina siffror, men det som verkligen lyfte modelleringen var en avancerad bildbearbetning av underlaget. 
   - Deskewing (Upprätning): Avancerad matematik användes för at beräkna bildens "moment" och räta upp siffror som är skrivna för snett. Detta eliminerar lutning som felkälla och gör att modellen kan fokusera på siffrans form.
   - Ultra-augmentation: Här var en riktig nyckel till bättre accuracy. Genom att använda skiftningar (1 pixel åt fyra håll), olika rotationer och  grader samt zoom (0,9 och 1,1) utökades de befintliga träningsdata från 56 000 till 616 000 rader!
   - Feature Extraction (HOG): Det här var ett sidospår som jag experimenterade med, men det visade sig att obearbetade pixlar med PCA presterade bättre på min nu mycket större datamängd.

6. Vad blev då resultatet? Min accuracy gick via mina olika experiment sakta uppåt och till slut landade det på 0.9928 - det innebär att bland de 14 000 testbilderna gissade modellen fel endast 101 gånger! 

Jakten på de sista tusendelarna bedrevs bl.a. via en TTA-hantering (Test-Time Augmentation). När det till slut var klart och min dator nästan tröttnat på alla beräkningar kom jag fram till high score: En accuracy på hela 0.9934 - bara 92 bilder i hela testsetet identifieras fel och det är för att de är riktigt dåliga (kolla själv, exempel finns här i mappstrukturen). 

Nästa steg
Projektets naturliga nästa steg är att applicera den tränade modellen på nya ritade eller uppladdade bilder. För att kunna hantera dem behöver de dock preprocessas för att få det format som modellen väntar sig.

Mitt script heter preprocess.py och är en liten bildbehandlingsmotor som översätter verkliga bilder till MNIST-standard genom flera steg:
	* Automatisk Invertering: Analyserar bildens hörn-pixel för att avgöra om användarens bild är en mörk siffra mot ljus bakgrund eller tvärtom och inverterar bilden vid behov så att siffran alltid presenteras som vit på svart bakgrund. 
	* Smart Cropping och isolering: Identifierar siffrans exakta koordinater (bounding box) för att klippa ut den från ritytan och använder ndimage.label för att räkna sammanhängande figurer (blobs).
	* Topologisk Analys (identifiering av "hål"): Beräknar antalet interna hål i figuren genom att jämföra siffran med en "fylld" version av sig själv det här var nyckeln till att kunna åsidosätta modellens felgissade siffror i flera fall.
	* Geometrisk Normalisering: Hittar siffrans ytterkanter och skalar om dess största dimension till 20 pixlar (med bibehållen proportion) innan den placeras centralt i en 28x28-ram.
	* Centrering (Center of Mass): Använder ndimage.center_of_mass för att finjustera siffrans position baserat på dess tyngdpunkt, vilket är avgörande för att efterlikna den statistiska fördelningen i MNIST-datasetet.
	* MNIST-ifiering: Mjukar upp bilden med ett Gaussiskt filter så att den får lagom mycket oskärpa för modellen.


### `predict.py` – Gränssnitt & Logik

Scriptet fungerar som projektets ansikte utåt och hanterar interaktionen via Streamlit:

* **Inmatningsmetoder:** Erbjuder både digital rityta (`st_canvas`) och filuppladdare.
* **TTA – Test Time Augmentation (Juryn):** För varje prediktion skapas 20 slumpmässiga varianter (rotation/skiftning) av bilden. Modellen röstar på samtliga, och resultatet presenteras som en "jury-enighet" i procent.
* **Session Management:** Använder `st.session_state` för att behålla resultat även vid rensning av ritytan.
* **Human-in-the-loop:** Innehåller en feedback-sektion där användaren kan korrigera modellen och spara problembilder för framtida träning.

---

## 2. Modellering & Optimering

### Val av Algoritm

Valet föll på en **Support Vector Classifier (SVC)** med RBF-kernel.

* **Datavolym:** Modellen är tränad på ca 735 000 rader, bestående av original-MNIST kombinerat med omfattande augmentering.
* **Träningstid:** Den slutgiltiga träningen tog 151 minuter, en medveten investering för att uppnå en extremt robust beslutsgräns i ett högdimensionellt rum.

### Heuristik & Logisk Verifiering

För att hantera gränsfall där den rent matematiska modellen tvekar, har en logisk kontrollinstans implementerats i `predict.py`:

* **Hål-detektering:** Om modellen gissar på en 5:a men topologin visar ett slutet hål, korrigeras resultatet till en 6:a.
* **Geometriska varningar:** Systemet varnar om en figur är misstänkt smal eller om flera oberoende figurer detekteras.

---

## 3. Active Learning: "The 6-Problem"

En central del av arbetet har varit att identifiera och åtgärda specifika svagheter i modellen:

* **Felanalys:** Genom en Confusion Matrix identifierades att handskrivna 6:or (utan tydligt "skaft") ofta misstogs för 5:or.
* **Data-injektion:** 67 unika problembilder (egna ritningar och MNIST-fel) samlades in och blåstes upp till 6 700 nya träningsexempel genom super-augmentering.
* **Resultat:** Efter omträning minskade antalet "6 som 5"-fel i testsetet från 2 till 1, och modellens säkerhet på användarens specifika handstil ökade till 100 % jury-enighet.


