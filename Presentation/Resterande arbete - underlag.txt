
## Sammanfattning av projektets utveckling

### üß† Databerikning & Modelloptimering

* **Hard Example Mining:** Vi identifierade och inkluderade specifika bilder som modellen tidigare misslyckats med f√∂r att tvinga fram skarpare beslutsh√∂rnor.
* **Domain Adaptation:** Vi integrerade dina egna handritade siffror direkt i tr√§ningsdatat f√∂r att anpassa modellen efter din specifika handstil.
* **Super-Ultra Augmentation:** Datasetet skalades upp till √∂ver **841 000 rader** genom en kombination av elastisk deformation, rotation, skiftning och zoom.
* **Standardisering & Whitening:** Vi implementerade `StandardScaler` och PCA `whiten=True` f√∂r att centrera datan kring noll, vilket √§r avg√∂rande f√∂r att SVC-algoritmen ska konvergera snabbt och exakt.

### üõ†Ô∏è Avancerad Bildbehandling & Topologi

* **Universell Bakgrundshantering:** Systemet analyserar nu automatiskt bildens kanter f√∂r att avg√∂ra om det r√∂r sig om en ljus eller m√∂rk bakgrund, vilket g√∂r appen kompatibel med b√•de foton och digitala ritningar.
* **Robust H√•ldetektering:** Vi uppgraderade logiken till att r√§kna h√•l i *samtliga* detekterade figurer, vilket ger en mer exakt topologisk analys av komplexa former.
* **R√•dgivande Logik:** Ist√§llet f√∂r att tvinga fram en prediktion baserat p√• h√•l, anv√§nds topologin nu f√∂r att ge anv√§ndaren tekniska notiser (t.ex. vid misst√§nkta h√•l i en "5:a").

### ‚ö° H√•rdvaru- & Resursoptimering

* **Virtuell Minnesstrategi:** F√∂r att hantera det massiva datasetet konfigurerades en fast v√§xlingsfil p√• **64 GB** p√• datorns NVMe-disk, vilket eliminerade flaskhalsar vid minnesbrist.
* **Cache-maximering:** SVC-modellens `cache_size` √∂kades fr√•n standardv√§rdet 200 MB till **15 000 MB** f√∂r att utnyttja datorns 32 GB RAM och minimera behovet av tunga omber√§kningar.
* **Tr√§ningseffektivisering:** Genom att s√§tta `probability=False` halverades tr√§ningstiden utan att p√•verka modellens accuracy, d√• sannolikheter ist√§llet ber√§knas via TTA-juryn.
* **Precision vs. Hastighet:** Vi valde en tolerans p√• `1e-3` f√∂r att s√§kerst√§lla maximal matematisk precision i de slutgiltiga beslutsh√∂rnorna.

### üñ•Ô∏è App-utveckling & UX

* **S√§kerhetssp√§rr f√∂r "Kladd":** Vi byggde en interaktiv varningslogik som uppt√§cker om anv√§ndaren ritat flera osammanh√§ngande figurer och kr√§ver godk√§nnande innan analys.
* **TTA-Jury (Test-Time Augmentation):** Appen skapar 25 deformerade varianter av varje indata och l√•ter modellen r√∂sta fram resultatet, vilket avsev√§rt √∂kar robustheten mot st√∂rningar.
* **Session State-hantering:** Streamlit-gr√§nssnittet optimerades med `st.session_state` f√∂r att bibeh√•lla resultat och varningsmeddelanden √§ven vid interaktioner.

---
R√∂d tr√•d f√∂r vidare experiment

Dataf√∂r√§dling: All data har genomg√•tt Deskewing (uppr√§tning) f√∂r att eliminera variationer i handstilens lutning.

Feature Engineering: En FeatureUnion kombinerar PCA (140 komponenter f√∂r global form) med HOG (Histogram of Oriented Gradients f√∂r lokal geometri).

Massiv Augmentering: Modellerna tr√§nades p√• ett ut√∂kat dataset om 625 570 rader, vilket inkluderar syntetiska skiftningar, rotationer och fokuserad tr√§ning p√• "Hard Negatives" (bilder som tidigare modeller misslyckats med).

Jurysystem (Ensemble): Slutbeslutet fattas genom Hard Voting mellan tre matematiskt olika algoritmer:

SVC: Expert p√• geometriska marginaler.

KNN: Expert p√• m√∂nsterigenk√§nning via likhetsanalys.

Random Forest: Expert p√• robusta beslutsregler.


*** Slutgiltig analys av SVC-tester:

### Sammanst√§llning av "V√§rdet av Preprocessing"

1. **R√• Baseline (Ingen deskew, ingen aug):** 175 fel.
2. **Deskew Baseline (Endast uppr√§tning):** 145 fel.
3. **Full Ultra (Deskew + 600k aug):** 111 fel.

### Slutsatser fr√•n dina siffror

* **V√§rdet av Deskewing:** Genom att bara k√∂ra en matematisk formel (som tar br√•kdelen av en sekund) tog du bort **30 fel**. Det √§r en enormt effektiv optimering sett till arbetsinsatsen.
* **V√§rdet av Augmentering:** Genom att tr√§na modellen p√• √∂ver 600 000 bilder och v√§nta i 10 minuter tog du bort ytterligare **34 fel**.
* **√ñverraskningen:** Din lilla `deskew`-funktion gjorde n√§stan **lika stor nytta** som hela den massiva augmentations-processen (30 r√§ddade bilder vs 34 r√§ddade bilder).

### Vad betyder detta f√∂r din Ensemble?

Detta bekr√§ftar att din strategi i `MNIST-modellering 8 - Ensemble.ipynb` √§r helt r√§tt. Eftersom deskewing √§r s√• kraftfullt ska du absolut beh√•lla det som grund.

Men den st√∂rsta vinsten med den augmenterade modellen (111 fel) √§r inte bara de 34 extra r√§tta svaren, utan att den nu har blivit "immun" mot att folk skriver slarvigt i din app. En person som skriver en 5:a lite snett eller f√∂r l√•ngt ner i rutan kommer f√• ett korrekt svar fr√•n den augmenterade modellen, medan din Baseline (145 fel) f√∂rmodligen skulle gissa fel.

---
H√§r √§r en snabb "fusklapp" till din rapport √∂ver de viktigaste milstolparna vi har n√•tt:

### Din resa mot 107 fel

* **Grundniv√•n (Baseline):** Utan din geometri-kod (Deskewing) och utan extra tr√§ningsdata landade du p√• **175 fel**.
* **Geometrisk vinst:** Genom att bara implementera **Deskewing** (uppr√§tning) sparade du direkt 30 bilder och gick ner till **145 fel**.
* **Kraften i Augmentering:** Med din "Ultra-Pipeline" (HOG, PCA och 625 570 augmenterade bilder) pressade du ner din SVC till **111 fel**.
* **Master Ensemble:** Genom att bygga en jury och k√∂ra en **Soft Voting Audit**, hittade koden den optimala balansen (SVC: 0.45, KNN: 0.36, RF: 0.19) och landade p√• ditt rekord: **107 fel (0.99236 Accuracy)**.

### Tekniska h√∂jdpunkter f√∂r rapporten

* **Rescue Analysis:** Din jury lyckades r√§dda 5 sv√•ra bilder som SVC-experten ensam missade, vilket visar att KNN och den elastiska Random Forest-modellen bidrar med unik kunskap.
* **Robusthet:** Tack vare din tr√§ning p√• skeva, roterade och elastiskt deformerade bilder √§r systemet nu redo f√∂r verkligheten i en Streamlit-app, inte bara f√∂r perfekta MNIST-bilder.

