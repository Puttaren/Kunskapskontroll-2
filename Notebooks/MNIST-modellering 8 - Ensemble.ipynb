{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bf88b7",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: IMPORTER ---\n",
    "import time\n",
    "notebook_start = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c8557",
   "metadata": {},
   "source": [
    "# --- CELL 2: DATALADDNING ---\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False, parser='auto')\n",
    "X = mnist[\"data\"] / 255.0  # Normalisera direkt\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 3: DESKEWING ---\n",
    "def deskew(image):\n",
    "    img = image.reshape(28, 28)\n",
    "    mu = ndimage.center_of_mass(img)\n",
    "    if np.isnan(mu).any(): return image\n",
    "    y_coords, x_coords = np.mgrid[:28, :28]\n",
    "    mu11 = np.sum((x_coords - mu[1]) * (y_coords - mu[0]) * img)\n",
    "    mu02 = np.sum((y_coords - mu[0])**2 * img)\n",
    "    if abs(mu02) < 1e-2: return image\n",
    "    skew = mu11 / mu02\n",
    "    matrix = np.array([[1, 0], [skew, 1]])\n",
    "    center = np.array([14, 14])\n",
    "    offset = center - np.dot(matrix, center)\n",
    "    return ndimage.affine_transform(img, matrix, offset=offset, order=1, mode='constant', cval=0).flatten()\n",
    "\n",
    "X_train_deskewed = np.array([deskew(img) for img in X_train])\n",
    "X_test_deskewed = np.array([deskew(img) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 4: DEFINITIONER OCH DATA-LADDNING (KOMPLETT) ---\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "# 1. DEFINIERA FUNKTIONER (Globala för att nås av TTA)\n",
    "def shift_image(image, dx, dy):\n",
    "    return ndimage.shift(image.reshape(28, 28), [dy, dx], cval=0, mode=\"constant\").flatten()\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    return ndimage.rotate(image.reshape(28, 28), angle, reshape=False, cval=0, mode=\"constant\").flatten()\n",
    "\n",
    "def zoom_image(image, zoom_factor):\n",
    "    img = image.reshape(28, 28)\n",
    "    zoomed = ndimage.zoom(img, zoom_factor, order=1)\n",
    "    h, w = img.shape\n",
    "    if zoom_factor < 1.0:\n",
    "        pad_h, pad_w = (h - zoomed.shape[0]) // 2, (w - zoomed.shape[1]) // 2\n",
    "        result = np.pad(zoomed, ((pad_h, h - zoomed.shape[0] - pad_h), (pad_w, w - zoomed.shape[1] - pad_w)), mode='constant')\n",
    "    else:\n",
    "        start_h, start_w = (zoomed.shape[0] - h) // 2, (zoomed.shape[1] - w) // 2\n",
    "        result = zoomed[start_h:start_h+h, start_w:start_w+w]\n",
    "    return result.flatten()\n",
    "\n",
    "def elastic_transform(image, alpha=8, sigma=3):\n",
    "    shape = (28, 28)\n",
    "    image_2d = image.reshape(shape)\n",
    "    random_state = np.random.RandomState(None)\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    y, x = np.mgrid[0:shape[0], 0:shape[1]]\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "    return map_coordinates(image_2d, indices, order=1, mode='constant', cval=0).flatten()\n",
    "\n",
    "# 2. CACHE-LOGIK\n",
    "fast_data_path = \"C:/mnist_data/mnist_augmented_rigid.joblib\"\n",
    "if not os.path.exists(\"C:/mnist_data\"):\n",
    "    os.makedirs(\"C:/mnist_data\")\n",
    "\n",
    "if os.path.exists(fast_data_path):\n",
    "    print(\">>> Laddar RIGID dataset från NVMe...\")\n",
    "    X_train_augmented, y_train_augmented = joblib.load(fast_data_path)\n",
    "else:\n",
    "    print(\">>> Skapar nytt rigid dataset...\")\n",
    "    X_train_aug = [X_train_deskewed]\n",
    "    y_train_aug = [y_train]\n",
    "\n",
    "    for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "        X_train_aug.append(np.apply_along_axis(shift_image, 1, X_train_deskewed, dx, dy))\n",
    "        y_train_aug.append(y_train)\n",
    "\n",
    "    for angle in (4, -4, 8, -8, 12, -12):\n",
    "        X_train_aug.append(np.apply_along_axis(rotate_image, 1, X_train_deskewed, angle))\n",
    "        y_train_aug.append(y_train)\n",
    "\n",
    "    for z in (0.9, 1.1):\n",
    "        X_train_aug.append(np.apply_along_axis(zoom_image, 1, X_train_deskewed, z))\n",
    "        y_train_aug.append(y_train)\n",
    "\n",
    "    X_train_augmented = np.concatenate(X_train_aug)\n",
    "    y_train_augmented = np.concatenate(y_train_aug)\n",
    "    shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "    X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "    y_train_augmented = y_train_augmented[shuffle_idx]\n",
    "    joblib.dump((X_train_augmented, y_train_augmented), fast_data_path)\n",
    "\n",
    "print(f\"Klart! Rader: {len(X_train_augmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 5: PCA ---\n",
    "pca = PCA(n_components=140, whiten=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 6: UPPDATERAD ENSEMBLE ---\n",
    "from sklearn.ensemble import ExtraTreesClassifier # Ofta vassare än standard RF\n",
    "\n",
    "# 1. Definiera experterna med dina vinnande inställningar\n",
    "svc_expert = SVC(C=25, kernel='rbf', gamma='scale', cache_size=2000)\n",
    "knn_expert = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=-1)\n",
    "rf_expert = ExtraTreesClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "\n",
    "# 2. Skapa juryn\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('svc', svc_expert), ('knn', knn_expert), ('rf', rf_expert)],\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. Pipeline med 140 PCA-komponenter (din vinnande siffra!)\n",
    "ensemble_pipeline = Pipeline([\n",
    "    ('feature', FeatureUnion([\n",
    "        ('pca', PCA(n_components=140, whiten=True)),\n",
    "        ('hog', HogTransformer())\n",
    "    ])),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ensemble', voting_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7: TRÄNING AV ENSEMBLE ---\n",
    "t0 = time.time()\n",
    "print(f\"Startar träning av juryn på {len(X_train_augmented)} rader...\")\n",
    "\n",
    "# Nu tränas SVC, RF och KNN parallellt tack vare n_jobs=-1 i VotingClassifier\n",
    "ensemble_pipeline.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "print(f\">>> Träning klar! Tid: {time.time() - t0:.1f} sekunder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa5f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 8: EVALUERING MED MICRO-TTA (SÄKER VERSION) ---\n",
    "t0 = time.time()\n",
    "\n",
    "# 1. Bas-prediktion (Ensemblens rena röstning)\n",
    "print(\"Steg 1: Ensemblen röstar på originalbilderna...\")\n",
    "y_pred_base = ensemble_pipeline.predict(X_test_deskewed)\n",
    "acc_base = np.mean(y_pred_base == y_test)\n",
    "print(f\"Accuracy (Ensemble Base): {acc_base:.5f}\")\n",
    "\n",
    "# 2. Micro-TTA Motor (Försiktig och statistiskt säker)\n",
    "def tta_predict_safe(image_flat, model, n_variants=30):\n",
    "    img_2d = image_flat.reshape(28, 28)\n",
    "    variants = [image_flat] # Originalet är viktigast\n",
    "    \n",
    "    for _ in range(n_variants - 1):\n",
    "        # Vi använder endast små variationer som inte förstör sifferns form\n",
    "        angle = np.random.uniform(-2, 2)\n",
    "        shift = np.random.uniform(-0.4, 0.4, size=2)\n",
    "        zoom = np.random.uniform(0.97, 1.03)\n",
    "        \n",
    "        v = ndimage.rotate(img_2d, angle, reshape=False, order=1, mode='constant', cval=0)\n",
    "        v = ndimage.shift(v, shift, mode='constant', cval=0)\n",
    "        \n",
    "        # Zoom-logik\n",
    "        z_v = ndimage.zoom(v, zoom, order=1)\n",
    "        if zoom > 1.0:\n",
    "            s = (z_v.shape[0] - 28) // 2\n",
    "            v = z_v[s:s+28, s:s+28]\n",
    "        else:\n",
    "            p = (28 - z_v.shape[0]) // 2\n",
    "            v = np.pad(z_v, ((p, 28-z_v.shape[0]-p), (p, 28-z_v.shape[1]-p)), mode='constant')\n",
    "        variants.append(v.flatten())\n",
    "    \n",
    "    all_preds = model.predict(np.array(variants))\n",
    "    counts = np.bincount(all_preds, minlength=10)\n",
    "    winner = np.argmax(counts)\n",
    "    \n",
    "    # SÄKERHETSSPÄRR: Om juryn inte är enig (>40%), behåll originalets gissning\n",
    "    if (counts[winner] / n_variants) < 0.40:\n",
    "        return all_preds[0]\n",
    "    return winner\n",
    "\n",
    "# 3. Kör TTA endast på de bilder där ensemblen missade\n",
    "mismatches = np.where(y_pred_base != y_test)[0]\n",
    "print(f\"\\nSteg 2: Analyserar {len(mismatches)} missar med Micro-TTA...\")\n",
    "\n",
    "y_pred_final = y_pred_base.copy()\n",
    "rescued = 0\n",
    "\n",
    "for idx in mismatches:\n",
    "    tta_vote = tta_predict_safe(X_test_deskewed[idx], ensemble_pipeline)\n",
    "    if tta_vote == y_test[idx]:\n",
    "        rescued += 1\n",
    "    y_pred_final[idx] = tta_vote\n",
    "\n",
    "acc_final = np.mean(y_pred_final == y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"RESULTAT: ENSEMBLE + MICRO-TTA\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Bas Accuracy:      {acc_base:.5f}\")\n",
    "print(f\"Bilder räddade:    {rescued}\")\n",
    "print(f\"Slutlig Accuracy:  {acc_final:.5f}\")\n",
    "print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
