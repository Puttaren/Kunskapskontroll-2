{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bf88b7",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: IMPORTER ---\n",
    "import time\n",
    "notebook_start = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c8557",
   "metadata": {},
   "source": [
    "# --- CELL 2: DATALADDNING ---\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False, parser='auto')\n",
    "X = mnist[\"data\"] / 255.0  # Normalisera direkt\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 3: DESKEWING ---\n",
    "def deskew(image):\n",
    "    img = image.reshape(28, 28)\n",
    "    mu = ndimage.center_of_mass(img)\n",
    "    if np.isnan(mu).any(): return image\n",
    "    y_coords, x_coords = np.mgrid[:28, :28]\n",
    "    mu11 = np.sum((x_coords - mu[1]) * (y_coords - mu[0]) * img)\n",
    "    mu02 = np.sum((y_coords - mu[0])**2 * img)\n",
    "    if abs(mu02) < 1e-2: return image\n",
    "    skew = mu11 / mu02\n",
    "    matrix = np.array([[1, 0], [skew, 1]])\n",
    "    center = np.array([14, 14])\n",
    "    offset = center - np.dot(matrix, center)\n",
    "    return ndimage.affine_transform(img, matrix, offset=offset, order=1, mode='constant', cval=0).flatten()\n",
    "\n",
    "X_train_deskewed = np.array([deskew(img) for img in X_train])\n",
    "X_test_deskewed = np.array([deskew(img) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 4: DEFINITIONER OCH DATA-LADDNING (KOMPLETT) ---\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "# 1. DEFINIERA FUNKTIONER (Globala för att nås av TTA)\n",
    "def shift_image(image, dx, dy):\n",
    "    return ndimage.shift(image.reshape(28, 28), [dy, dx], cval=0, mode=\"constant\").flatten()\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    return ndimage.rotate(image.reshape(28, 28), angle, reshape=False, cval=0, mode=\"constant\").flatten()\n",
    "\n",
    "def zoom_image(image, zoom_factor):\n",
    "    img = image.reshape(28, 28)\n",
    "    zoomed = ndimage.zoom(img, zoom_factor, order=1)\n",
    "    h, w = img.shape\n",
    "    if zoom_factor < 1.0:\n",
    "        pad_h, pad_w = (h - zoomed.shape[0]) // 2, (w - zoomed.shape[1]) // 2\n",
    "        result = np.pad(zoomed, ((pad_h, h - zoomed.shape[0] - pad_h), (pad_w, w - zoomed.shape[1] - pad_w)), mode='constant')\n",
    "    else:\n",
    "        start_h, start_w = (zoomed.shape[0] - h) // 2, (zoomed.shape[1] - w) // 2\n",
    "        result = zoomed[start_h:start_h+h, start_w:start_w+w]\n",
    "    return result.flatten()\n",
    "\n",
    "def elastic_transform(image, alpha=8, sigma=3):\n",
    "    shape = (28, 28)\n",
    "    image_2d = image.reshape(shape)\n",
    "    random_state = np.random.RandomState(None)\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    y, x = np.mgrid[0:shape[0], 0:shape[1]]\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "    return map_coordinates(image_2d, indices, order=1, mode='constant', cval=0).flatten()\n",
    "\n",
    "# 2. CACHE-LOGIK\n",
    "fast_data_path = \"C:/mnist_data/mnist_svc_hog_max.joblib\"\n",
    "if not os.path.exists(\"C:/mnist_data\"):\n",
    "    os.makedirs(\"C:/mnist_data\")\n",
    "\n",
    "if os.path.exists(fast_data_path):\n",
    "    print(\">>> Laddar RIGID dataset från NVMe...\")\n",
    "    X_train_augmented, y_train_augmented = joblib.load(fast_data_path)\n",
    "else:\n",
    "    print(\">>> Skapar nytt rigid dataset...\")\n",
    "    X_train_aug = [X_train_deskewed]\n",
    "    y_train_aug = [y_train]\n",
    "\n",
    "    for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "        X_train_aug.append(np.apply_along_axis(shift_image, 1, X_train_deskewed, dx, dy))\n",
    "        y_train_aug.append(y_train)\n",
    "\n",
    "    for angle in (4, -4, 8, -8, 12, -12):\n",
    "        X_train_aug.append(np.apply_along_axis(rotate_image, 1, X_train_deskewed, angle))\n",
    "        y_train_aug.append(y_train)\n",
    "\n",
    "    for z in (0.9, 1.1):\n",
    "        X_train_aug.append(np.apply_along_axis(zoom_image, 1, X_train_deskewed, z))\n",
    "        y_train_aug.append(y_train)\n",
    "\n",
    "    X_train_augmented = np.concatenate(X_train_aug)\n",
    "    y_train_augmented = np.concatenate(y_train_aug)\n",
    "    shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "    X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "    y_train_augmented = y_train_augmented[shuffle_idx]\n",
    "    joblib.dump((X_train_augmented, y_train_augmented), fast_data_path)\n",
    "\n",
    "print(f\"Klart! Rader: {len(X_train_augmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 5: PCA ---\n",
    "pca = PCA(n_components=140, whiten=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 6: SMART ENSEMBLE (Laddar din vinnande SVC) ---\n",
    "\n",
    "# 1. Försök ladda din befintliga succé-modell\n",
    "model_path = 'mnist_svc_hog_max.joblib'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\">>> Hittade guld-modellen ({model_path}). Laddar in SVC-experten...\")\n",
    "    # Vi plockar ut SVC-delen direkt ur din sparade pipeline\n",
    "    loaded_pipe = joblib.load(model_path)\n",
    "    svc_expert = loaded_pipe.named_steps['svc']\n",
    "else:\n",
    "    print(\">>> VARNING: Hittade ingen sparad fil. Skapar en ny SVC (C=25).\")\n",
    "    svc_expert = SVC(C=25, kernel='rbf', cache_size=2000)\n",
    "\n",
    "# 2. Definiera de nya kollegorna (KNN och RF)\n",
    "# De här behöver tränas från grunden för att lära sig dina HOG-features\n",
    "knn_expert = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=-1)\n",
    "rf_expert = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "\n",
    "# 3. Skapa juryn\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svc_expert), \n",
    "        ('knn', knn_expert), \n",
    "        ('rf', rf_expert)\n",
    "    ],\n",
    "    voting='hard',\n",
    "    n_jobs=-1 # Parallell träning!\n",
    ")\n",
    "\n",
    "# 4. Den kompletta pipelinen (HOG + PCA 140)\n",
    "ensemble_pipeline = Pipeline([\n",
    "    ('feature', FeatureUnion([\n",
    "        ('pca', PCA(n_components=140, whiten=True)),\n",
    "        ('hog', HogTransformer())\n",
    "    ])),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ensemble', voting_clf)\n",
    "])\n",
    "\n",
    "print(\"Ensemblen är nu redo med din vinnande SVC som ordförande!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7: TRÄNING AV ENSEMBLE ---\n",
    "t0 = time.time()\n",
    "print(f\"Startar träning av juryn på {len(X_train_augmented)} rader...\")\n",
    "\n",
    "# Nu tränas SVC, RF och KNN parallellt tack vare n_jobs=-1 i VotingClassifier\n",
    "ensemble_pipeline.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "print(f\">>> Träning klar! Tid: {time.time() - t0:.1f} sekunder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa5f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 8: REN EVALUERING ---\n",
    "t0 = time.time()\n",
    "\n",
    "print(\"Genomför slutgiltig prediktion med Master Ensemble...\")\n",
    "y_pred = ensemble_pipeline.predict(X_test_deskewed)\n",
    "\n",
    "final_acc = np.mean(y_pred == y_test)\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"RESULTAT UTAN TTA\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Accuracy: {final_acc:.5f}\")\n",
    "print(f\"Antal fel: {np.sum(y_pred != y_test)} av 14 000\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Visa de 5 svåraste bilderna\n",
    "still_wrong = np.where(y_pred != y_test)[0]\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, idx in enumerate(still_wrong[:5]):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X_test_deskewed[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Sann: {y_test[idx]}\\nGissad: {y_pred[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
