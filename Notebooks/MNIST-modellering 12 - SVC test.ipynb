{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfcb69e",
   "metadata": {},
   "source": [
    "# SVC-test av augmentering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7ea9f",
   "metadata": {},
   "source": [
    "\n",
    "## Importera nödvändiga paket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4d6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Tid för denna cell: 3.4 sekunder\n",
      ">>> Total tid sedan start: 0 minuter och 3 sekunder\n"
     ]
    }
   ],
   "source": [
    "# Av eget intresse vill jag gärna veta hur lång tid olika saker tar.\n",
    "import time\n",
    "notebook_start = time.time()  \n",
    "t0 = time.time()\n",
    "\n",
    "# Skippa varningar\n",
    "import warnings\n",
    "\n",
    "# Boosta prestandan\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "# Paket för datahantering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Dataset och modeller\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split #, GridSearchCV, cross_val_score\n",
    "\n",
    "# Preprocessing/pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "# Dimensionsreducering\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Feature-bearbetning\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Data augmentation och förbehandling - stabil version för SciPy\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "\n",
    "# Bildbehandling\n",
    "from PIL import Image\n",
    "\n",
    "# Modeller \n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# För export av modellen/scalern för vidare användning i Streamlit-appen\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Slutrapport\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tillfällig (om jag inte glömmer det) sänkning av prioriteten så datorn orkar annat\n",
    "os.environ['OMP_NUM_THREADS'] = '8' \n",
    "os.environ['MKL_NUM_THREADS'] = '8'\n",
    "\n",
    "cell_time = time.time() - t0\n",
    "total_time = time.time() - notebook_start\n",
    "mins, secs = divmod(total_time, 60)\n",
    "\n",
    "print(f\">>> Tid för denna cell: {cell_time:.1f} sekunder\")\n",
    "print(f\">>> Total tid sedan start: {int(mins)} minuter och {int(secs)} sekunder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad1d73",
   "metadata": {},
   "source": [
    "## Läs in MNISt-datasetet och splitta det. \n",
    "\n",
    "*//Best practice: splitta ut testsetet direkt//*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f736f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      ">>> Tid för denna cell: 2.5 sekunder\n",
      ">>> Total tid sedan start: 0 minuter och 5 sekunder\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Läs in alla MNIST-data\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False, parser='auto')\n",
    "X = mnist[\"data\"]              \n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "# Splitta (80/20) med stratifiering för jämna klassfördelningar\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Normalisering (en riktigt bra grej för både PCA och SVC!)\n",
    "# Genom att dela med 255.0 blir alla värden mellan 0 och 1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "cell_time = time.time() - t0\n",
    "total_time = time.time() - notebook_start\n",
    "mins, secs = divmod(total_time, 60)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\">>> Tid för denna cell: {cell_time:.1f} sekunder\")\n",
    "print(f\">>> Total tid sedan start: {int(mins)} minuter och {int(secs)} sekunder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911692f5",
   "metadata": {},
   "source": [
    "HoG ska boosta accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f881deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        def local_hog(img_flat):\n",
    "            return hog(img_flat.reshape(28, 28), \n",
    "                       orientations=self.orientations, \n",
    "                       pixels_per_cell=self.pixels_per_cell, \n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       visualize=False)\n",
    "        \n",
    "        return np.array([local_hog(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b0475",
   "metadata": {},
   "source": [
    "Definitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c758306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Tid för denna cell: 0.0 sekunder\n",
      ">>> Total tid sedan start: 0 minuter och 5 sekunder\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "def deskew(image):\n",
    "    # Räta upp lutande siffror \n",
    "    img = image.reshape(28, 28)\n",
    "    \n",
    "    # Skapa koordinat-matriser (y för rader, x för kolumner)\n",
    "    y, x = np.mgrid[:28, :28]\n",
    "    \n",
    "    # Hitta tyngdpunkten (Center of Mass) med ndimage\n",
    "    mu = ndimage.center_of_mass(img)\n",
    "    if np.isnan(mu).any(): # Om bilden är tom\n",
    "        return img.flatten()\n",
    "    \n",
    "    # Beräkna centrala moments (mu11 = kovarians, mu02 = varians i y-led)\n",
    "    mu11 = np.sum((x - mu[1]) * (y - mu[0]) * img)\n",
    "    mu02 = np.sum((y - mu[0])**2 * img)\n",
    "    \n",
    "    # Om variansen är för liten lutar siffran inte eller är för tunn\n",
    "    if abs(mu02) < 1e-2:\n",
    "        return img.flatten()\n",
    "    \n",
    "    # Skew-faktorn (förskjutning av x per enhet y)\n",
    "    skew = mu11 / mu02\n",
    "    \n",
    "    # Här rätas x upp genom subtrahering av skew * y\n",
    "    # Matrisen blir [[1, 0], [skew, 1]] med SciPys omvända ordning.\n",
    "    matrix = np.array([[1, 0], [skew, 1]])\n",
    "    \n",
    "    # Offset för att rotera/skeva kring bildens centrum (14, 14)\n",
    "    center = np.array([14, 14])\n",
    "    offset = center - np.dot(matrix, center)\n",
    "    \n",
    "    # Transformation\n",
    "    img_deskewed = ndimage.affine_transform(img, matrix, offset=offset, order=1, mode='constant', cval=0)\n",
    "    return img_deskewed.flatten()\n",
    "\n",
    "def shift_image(image, dx, dy):\n",
    "    return ndimage.shift(image.reshape(28, 28), [dy, dx], cval=0, mode=\"constant\").flatten()\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    return ndimage.rotate(image.reshape(28, 28), angle, reshape=False, cval=0, mode=\"constant\").flatten()\n",
    "\n",
    "def zoom_image(image, factor):\n",
    "    rescaled = ndimage.zoom(image.reshape(28, 28), factor)\n",
    "    if factor > 1.0: # Zooma in (klipp)\n",
    "        start = int((rescaled.shape[0] - 28) / 2)\n",
    "        final = rescaled[start:start+28, start:start+28]\n",
    "    else: # Zooma ut (padda)\n",
    "        pad = int((28 - rescaled.shape[0]) / 2)\n",
    "        final = np.pad(rescaled, ((pad, 28-rescaled.shape[0]-pad), (pad, 28-rescaled.shape[1]-pad)), mode='constant')\n",
    "    return final.flatten()\n",
    "\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "\n",
    "def elastic_transform(image, alpha=8, sigma=3.5):\n",
    "    \"\"\"\n",
    "    Kirurgisk Elastic Deformation för MNIST.\n",
    "    alpha: Kontrollerar intensiteten i deformationen (hur långt pixlarna flyttas).\n",
    "    sigma: Kontrollerar mjukheten (högre värde = mjukare kurvor, lägre = taggigare).\n",
    "    \"\"\"\n",
    "    # Vi utgår från att bilden kommer in som en platt array (784,)\n",
    "    shape = (28, 28)\n",
    "    image_reshaped = image.reshape(shape)\n",
    "    \n",
    "    # Skapa ett slumpmässigt fält för förskjutning\n",
    "    # Vi använder en lokal RandomState för att inte störa globala frön om det behövs\n",
    "    random_state = np.random.RandomState(None)\n",
    "    \n",
    "    # Generera brus och filtrera det med Gaussian för att få mjuka \"vågor\"\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    # Skapa ett koordinatnät\n",
    "    x, y = np.mgrid[0:shape[0], 0:shape[1]]\n",
    "    \n",
    "    # Mappa om bildens pixlar till de nya koordinaterna\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "    distorted_image = map_coordinates(image_reshaped, indices, order=1, mode='reflect')\n",
    "    \n",
    "    return distorted_image.flatten()\n",
    "\n",
    "cell_time = time.time() - t0\n",
    "total_time = time.time() - notebook_start\n",
    "mins, secs = divmod(total_time, 60)\n",
    "\n",
    "print(f\">>> Tid för denna cell: {cell_time:.1f} sekunder\")\n",
    "print(f\">>> Total tid sedan start: {int(mins)} minuter och {int(secs)} sekunder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c8032",
   "metadata": {},
   "source": [
    "Här kommer lite extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9c35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hittade 18 st .png-filer i collected_data...\n",
      "------------------------------\n",
      "Nytt antal i X_train: 56018 (ökning med 18)\n",
      "Rätar upp det nya kombinerade träningssetet (Deskewing)...\n",
      ">>> Tid för denna cell: 4.5 sekunder\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Sökvägar\n",
    "paths = {\n",
    "    'custom': 'collected_data'\n",
    "}\n",
    "\n",
    "X_extra = []\n",
    "y_extra = []\n",
    "\n",
    "def process_and_add(folder, label_pos, split_char='_'):\n",
    "    added_count = 0\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"VARNING: Mappen '{folder}' hittades inte!\")\n",
    "        return 0\n",
    "    \n",
    "    files = [f for f in os.listdir(folder) if f.endswith(\".png\")]\n",
    "    print(f\"Hittade {len(files)} st .png-filer i {folder}...\")\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            # Extrahera label baserat på filnamnsstruktur\n",
    "            parts = filename.split(split_char)\n",
    "            # Hitta siffran i filnamnet\n",
    "            label = None\n",
    "            for p in parts:\n",
    "                if p.isdigit() and len(p) == 1:\n",
    "                    label = int(p)\n",
    "                    break\n",
    "            \n",
    "            if label is None:\n",
    "                # Fallback\n",
    "                label = int(parts[label_pos])\n",
    "            \n",
    "            # Bearbeta bilden till MNIST-format\n",
    "            img = Image.open(os.path.join(folder, filename)).convert('L')\n",
    "            img = img.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "            img_array = np.array(img).astype(np.float32) / 255.0\n",
    "            \n",
    "            # MNIST-standard: Vit siffra på svart bakgrund\n",
    "            # Kolla medianen av kanterna\n",
    "            edge_median = np.median(np.concatenate([img_array[0,:], img_array[-1,:], img_array[:,0], img_array[:,-1]]))\n",
    "            # Ljus bakgrund -> Invertera\n",
    "            if edge_median > 0.5: \n",
    "                img_array = 1.0 - img_array\n",
    "                \n",
    "            X_extra.append(img_array.flatten())\n",
    "            y_extra.append(label)\n",
    "            added_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Skippar {filename}: {e}\")\n",
    "            \n",
    "    return added_count\n",
    "\n",
    "# Läs in användarskapade bilder\n",
    "count_c = process_and_add(paths['custom'], label_pos=1)\n",
    "\n",
    "if len(X_extra) > 0:\n",
    "    X_train = np.vstack([X_train, np.array(X_extra)])\n",
    "    y_train = np.concatenate([y_train, np.array(y_extra)])\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Nytt antal i X_train: {len(X_train)} (ökning med {len(X_extra)})\")\n",
    "else:\n",
    "    print(\"-\" * 30)\n",
    "    print(\"INGA EXTRA BILDER. Kontrollera mappen!\")\n",
    "\n",
    "# Uppdatera X_train_deskewed med alla bilder\n",
    "print(\"Rätar upp det nya kombinerade träningssetet (Deskewing)...\")\n",
    "X_train_deskewed = np.array([deskew(img) for img in X_train])\n",
    "\n",
    "cell_time = time.time() - t0\n",
    "print(f\">>> Tid för denna cell: {cell_time:.1f} sekunder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd909836",
   "metadata": {},
   "source": [
    "Hard negative mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe63e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letar efter ALLA svåra bilder i träningssetet via Cross-Validation...\n",
      "------------------------------\n",
      "IDENTIFIERING KLAR: Hittade 852 svåra bilder (ca 1.52% av datat).\n",
      "Detta är en 'ärlig' felmarginal på träningsdatat.\n",
      ">>> 852 bilder sparade i 'mnist_errors'.\n",
      ">>> Tid: 35.1 sekunder\n"
     ]
    }
   ],
   "source": [
    "# --- NY CELL 21: HITTA ALLA ÄRLIGA FEL (CROSS-VALIDATION) ---\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"Letar efter ALLA svåra bilder i träningssetet via Cross-Validation...\")\n",
    "\n",
    "# Vi använder en något snabbare inställning för att inte vänta hela dagen\n",
    "# Men tillräckligt bra för att hitta de riktiga felen\n",
    "error_finder_pipe = Pipeline([\n",
    "    ('pca', PCA(n_components=80, whiten=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(C=5, kernel='rbf'))\n",
    "])\n",
    "\n",
    "# cross_val_predict gör att modellen gissar på bilder den INTE tränat på just då\n",
    "# cv=3 betyder att den kör 3 rundor. Tar ca 1-2 minuter.\n",
    "y_train_cv_pred = cross_val_predict(error_finder_pipe, X_train_deskewed, y_train, cv=3, n_jobs=-1)\n",
    "\n",
    "# Identifiera alla ärliga fel\n",
    "hard_indices = np.where(y_train_cv_pred != y_train)[0]\n",
    "X_hard = X_train_deskewed[hard_indices]\n",
    "y_hard = y_train[hard_indices]\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"IDENTIFIERING KLAR: Hittade {len(X_hard)} svåra bilder (ca {len(X_hard)/len(y_train)*100:.2f}% av datat).\")\n",
    "print(f\"Detta är en 'ärlig' felmarginal på träningsdatat.\")\n",
    "\n",
    "# Exportera dessa till mappen\n",
    "if not os.path.exists('mnist_errors'):\n",
    "    os.makedirs('mnist_errors')\n",
    "\n",
    "for i, (img_flat, label) in enumerate(zip(X_hard, y_hard)):\n",
    "    img_array = (img_flat.reshape(28, 28) * 255).astype(np.uint8)\n",
    "    img = Image.fromarray(img_array)\n",
    "    filename = f\"hard_negative_{label}_idx{i}.png\"\n",
    "    img.save(os.path.join('mnist_errors', filename))\n",
    "\n",
    "print(f\">>> {len(X_hard)} bilder sparade i 'mnist_errors'.\")\n",
    "print(f\">>> Tid: {time.time() - t0:.1f} sekunder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbb368",
   "metadata": {},
   "source": [
    "# Augmentering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e811f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Skapar elastiska kopior för klasserna: [3, 4, 5, 7, 9]...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_base_for_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>>> Skapar elastiska kopior för klasserna: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Vi lägger till direkt i de befintliga listorna istället för att vstacka sen\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mX_base_for_aug\u001b[49m, y_base_for_aug):\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m target_classes:\n\u001b[32m     36\u001b[39m         \u001b[38;5;66;03m# Skapa första elastiska kopian\u001b[39;00m\n\u001b[32m     37\u001b[39m         X_train_augmented.append(elastic_transform(image, alpha=\u001b[32m8\u001b[39m, sigma=\u001b[32m3.5\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'X_base_for_aug' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"t0 = time.time()\n",
    "\n",
    "# Vi börjar med de vanliga bilderna PLUS de svåra bilderna (en extra kopia)\n",
    "X_base_for_aug = np.vstack([X_train_deskewed, X_hard])\n",
    "y_base_for_aug = np.concatenate([y_train, y_hard])\n",
    "\n",
    "X_train_augmented = [image for image in X_base_for_aug]\n",
    "y_train_augmented = [label for label in y_base_for_aug]\n",
    "\n",
    "print(f\"Startar ultra-augmentering på {len(X_base_for_aug)} bilder (inkl. {len(X_hard)} svåra)...\")\n",
    "\n",
    "# Vi kör dina standard-augmentationer på hela den utökade potten\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    for image, label in zip(X_base_for_aug, y_base_for_aug):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "for angle in (-8, -4, 4, 8):\n",
    "    for image, label in zip(X_base_for_aug, y_base_for_aug):\n",
    "        X_train_augmented.append(rotate_image(image, angle))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "for factor in (0.9, 1.1):\n",
    "    for image, label in zip(X_base_for_aug, y_base_for_aug):\n",
    "        X_train_augmented.append(zoom_image(image, factor))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "# --- OPTIMERAT BLOCK: MÅLINRIKTAD ELASTISK AUGMENTERING ---\n",
    "t_aug = time.time()\n",
    "target_classes = [3, 4, 5, 7, 9]\n",
    "print(f\">>> Skapar elastiska kopior för klasserna: {target_classes}...\")\n",
    "\n",
    "# Vi lägger till direkt i de befintliga listorna istället för att vstacka sen\n",
    "for image, label in zip(X_base_for_aug, y_base_for_aug):\n",
    "    if label in target_classes:\n",
    "        # Skapa första elastiska kopian\n",
    "        X_train_augmented.append(elastic_transform(image, alpha=8, sigma=3.5))\n",
    "        y_train_augmented.append(label)\n",
    "        # Skapa andra elastiska kopian\n",
    "        X_train_augmented.append(elastic_transform(image, alpha=8, sigma=3.5))\n",
    "        y_train_augmented.append(label)\n",
    "# NU konverterar vi allt till numpy-arrayer en enda gång (sparar massor av RAM)\n",
    "print(\"Konverterar till slutgiltiga arrayer...\")\n",
    "X_train_augmented = np.array(X_train_augmented, dtype='float32')\n",
    "y_train_augmented = np.array(y_train_augmented)\n",
    "\n",
    "# Spara till C:\n",
    "save_path = \"C:/mnist_data/mnist_augmented_boosted.joblib\"\n",
    "joblib.dump((X_train_augmented, y_train_augmented), save_path)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Ny total datamängd: {len(X_train_augmented)} rader\") # Kommer vara ca 680 000+\n",
    "print(f\">>> Tid för hela augmenteringen: {time.time() - t0:.1f} sekunder\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe56a6",
   "metadata": {},
   "source": [
    "Preparera testsetet så att jämförelsen blir rättvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fb0207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      ">>> Sökningen klar på 1.2 sekunder.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Här rätas testbilderna upp för att matcha modellen\n",
    "X_test_deskewed = np.array([deskew(img) for img in X_test])\n",
    "\n",
    "X_test_deskewed = X_test_deskewed.astype('float32')\n",
    "\n",
    "cell_time = time.time() - t0\n",
    "print(\"-\" * 40)\n",
    "print(f\">>> Sökningen klar på {cell_time:.1f} sekunder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe9d10",
   "metadata": {},
   "source": [
    "## Dags att skapa en pipeline som används i hela projektet, en \"single source of truth\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20411610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Pipeline definierad! Tid: 0.0 sekunder\n",
      ">>> Total tid sedan start: 1 minuter och 41 sekunder\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Detta är vår \"Ultra-Pipeline\"\n",
    "# Vi kombinerar Notebook 3:s PCA med form-analys från HOG\n",
    "final_pipe_ultra = Pipeline([\n",
    "    ('feature', FeatureUnion([\n",
    "        ('pca', PCA(n_components=65, whiten=True)), # Från Notebook 3\n",
    "        ('hog', HogTransformer())      # Vår nya form-förstärkare\n",
    "    ])),\n",
    "    ('scaler', StandardScaler()),      # Livsviktig för att balansera PCA och HOG\n",
    "    ('svc', SVC(\n",
    "        C=25, \n",
    "        kernel='rbf', \n",
    "        gamma='scale', \n",
    "        cache_size=500,              \n",
    "        probability=True,\n",
    "        tol=1e-2,\n",
    "        shrinking=True, \n",
    "        verbose=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "cell_time = time.time() - t0\n",
    "total_time = time.time() - notebook_start\n",
    "mins, secs = divmod(total_time, 60)\n",
    "\n",
    "print(f\">>> Pipeline definierad! Tid: {cell_time:.1f} sekunder\")\n",
    "print(f\">>> Total tid sedan start: {int(mins)} minuter och {int(secs)} sekunder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b0599b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- CELL 28: OPTIMERAD TRÄNING (MINNESSNÅL VERSION) ---\\nimport gc \\nimport time\\n\\nt0 = time.time()\\n\\n# 1. Förbered data UTAN att skapa en kopia\\n# Vi hoppar över .astype(\\'float32\\') eftersom Cell 25 redan gjorde det jobbet.\\n# På så sätt sparar vi ca 2.5 GB RAM omedelbart.\\nX_train_final = X_train_augmented \\ny_train_final = y_train_augmented\\n\\n# 2. RADIKAL MINNESRENSNING\\n# Vi tar bort referensen till listan och tvingar Python att frigöra RAM\\nif \\'X_train_augmented\\' in locals():\\n    del X_train_augmented\\ngc.collect() \\n\\n# 3. FINJUSTERA PIPELINEN FÖR ATT KLARA ZOOM + 681k RADER\\n# Vi sänker cache_size drastiskt för att ge plats åt probability-kalkylen.\\nfinal_pipe_ultra.set_params(\\n    feature__pca__n_components=140,\\n    feature__pca__whiten=True,\\n    svc__C=25, \\n    svc__cache_size=1000,         # Sänkt från 3000 för att rädda RAM\\n    svc__probability=True,       # Måste vara med här för Soft Voting!\\n    svc__tol=1e-3,               \\n    svc__shrinking=True,         # Hjälper till att hålla nere antalet support-vektorer\\n    svc__verbose=True\\n)\\n\\nprint(f\"\\n>>> STARTAR TRÄNING: {len(X_train_final)} rader.\")\\n\\ntry:\\n    # Denna rad gör det tunga jobbet (räkna med 45-60 minuter pga färre trådar)\\n    final_pipe_ultra.fit(X_train_final, y_train_final)\\n    print(\"\\nSUCCESS! Modellen är tränad.\")\\nexcept MemoryError:\\n    print(\"\\nAI-Haveri: RAM-minnet räckte inte till. Stäng Trados/Zoom och prova igen.\")\\n    gc.collect()\\n\\n# 4. SLUTGILTIG UTVÄRDERING\\nprint(\"\\nGenomför slutexamen på testdata...\")\\nbase_accuracy = final_pipe_ultra.score(X_test_deskewed, y_test)\\ny_pred_tmp = final_pipe_ultra.predict(X_test_deskewed)\\nnum_errors = np.sum(y_pred_tmp != y_test)\\n\\nprint(\"\\n\" + \"=\"*40)\\nprint(f\"RESULTAT: BOOSTED SVC\")\\nprint(\"-\" * 40)\\nprint(f\"Accuracy:      {base_accuracy:.5f}\")\\nprint(f\"Antal fel:     {num_errors} av {len(y_test)}\")\\nprint(\"=\"*40)\\n\\ncell_time = time.time() - t0\\nprint(f\">>> Full träning och test klar på: {cell_time/60:.1f} minuter\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- CELL 28: OPTIMERAD TRÄNING (MINNESSNÅL VERSION) ---\n",
    "import gc \n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# 1. Förbered data UTAN att skapa en kopia\n",
    "# Vi hoppar över .astype('float32') eftersom Cell 25 redan gjorde det jobbet.\n",
    "# På så sätt sparar vi ca 2.5 GB RAM omedelbart.\n",
    "X_train_final = X_train_augmented \n",
    "y_train_final = y_train_augmented\n",
    "\n",
    "# 2. RADIKAL MINNESRENSNING\n",
    "# Vi tar bort referensen till listan och tvingar Python att frigöra RAM\n",
    "if 'X_train_augmented' in locals():\n",
    "    del X_train_augmented\n",
    "gc.collect() \n",
    "\n",
    "# 3. FINJUSTERA PIPELINEN FÖR ATT KLARA ZOOM + 681k RADER\n",
    "# Vi sänker cache_size drastiskt för att ge plats åt probability-kalkylen.\n",
    "final_pipe_ultra.set_params(\n",
    "    feature__pca__n_components=140,\n",
    "    feature__pca__whiten=True,\n",
    "    svc__C=25, \n",
    "    svc__cache_size=1000,         # Sänkt från 3000 för att rädda RAM\n",
    "    svc__probability=True,       # Måste vara med här för Soft Voting!\n",
    "    svc__tol=1e-3,               \n",
    "    svc__shrinking=True,         # Hjälper till att hålla nere antalet support-vektorer\n",
    "    svc__verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n>>> STARTAR TRÄNING: {len(X_train_final)} rader.\")\n",
    "\n",
    "try:\n",
    "    # Denna rad gör det tunga jobbet (räkna med 45-60 minuter pga färre trådar)\n",
    "    final_pipe_ultra.fit(X_train_final, y_train_final)\n",
    "    print(\"\\nSUCCESS! Modellen är tränad.\")\n",
    "except MemoryError:\n",
    "    print(\"\\nAI-Haveri: RAM-minnet räckte inte till. Stäng Trados/Zoom och prova igen.\")\n",
    "    gc.collect()\n",
    "\n",
    "# 4. SLUTGILTIG UTVÄRDERING\n",
    "print(\"\\nGenomför slutexamen på testdata...\")\n",
    "base_accuracy = final_pipe_ultra.score(X_test_deskewed, y_test)\n",
    "y_pred_tmp = final_pipe_ultra.predict(X_test_deskewed)\n",
    "num_errors = np.sum(y_pred_tmp != y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"RESULTAT: BOOSTED SVC\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Accuracy:      {base_accuracy:.5f}\")\n",
    "print(f\"Antal fel:     {num_errors} av {len(y_test)}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "cell_time = time.time() - t0\n",
    "print(f\">>> Full träning och test klar på: {cell_time/60:.1f} minuter\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4bf1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> STARTAR BASELINE-TRÄNING: 56018 rader.\n",
      "Detta bör ta ca 1-2 minuter istället för 10+.\n",
      "\n",
      "SUCCESS! Baseline-modellen klar på 0.2 minuter.\n"
     ]
    }
   ],
   "source": [
    "# --- NY CELL: BASELINE-TRÄNING (UTAN AUGMENTERING) ---\n",
    "import gc \n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# 1. Använd endast originaldata (56 000 rader) som rätats upp (Deskewed)\n",
    "# Vi hoppar över de 681 000 augmenterade raderna helt.\n",
    "X_train_final = X_train_deskewed.astype('float32')\n",
    "y_train_final = y_train\n",
    "\n",
    "# 2. RENSA MINNET\n",
    "# Vi tar bort eventuella rester av det stora augmenterade setet\n",
    "if 'X_train_augmented' in locals():\n",
    "    del X_train_augmented\n",
    "gc.collect() \n",
    "\n",
    "# 3. KONFIGURERA PIPELINEN FÖR BASELINE\n",
    "# Vi använder n=65 eftersom din sweep visade att det är mest effektivt.\n",
    "final_pipe_ultra.set_params(\n",
    "    feature__pca__n_components=65, \n",
    "    feature__pca__whiten=True,\n",
    "    svc__C=25, \n",
    "    svc__probability=True,         # Vi behåller True så du kan använda den i juryn sen\n",
    "    svc__cache_size=2000,          # Kan vara högre nu när vi har färre rader\n",
    "    svc__verbose=True\n",
    ")\n",
    "\n",
    "print(f\">>> STARTAR BASELINE-TRÄNING: {len(X_train_final)} rader.\")\n",
    "print(\"Detta bör ta ca 1-2 minuter istället för 10+.\")\n",
    "\n",
    "# 4. TRÄNA\n",
    "final_pipe_ultra.fit(X_train_final, y_train_final)\n",
    "\n",
    "print(f\"\\nSUCCESS! Baseline-modellen klar på {(time.time() - t0)/60:.1f} minuter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4deaf3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "BASELINE SVC RESULTAT\n",
      "------------------------------\n",
      "Accuracy:  0.98964\n",
      "Antal fel: 145 av 14000\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# --- NY CELL: BASELINE-RESULTAT ---\n",
    "\n",
    "# 1. Beräkna accuracy direkt\n",
    "baseline_acc = final_pipe_ultra.score(X_test_deskewed, y_test)\n",
    "\n",
    "# 2. Beräkna antal fel\n",
    "y_pred = final_pipe_ultra.predict(X_test_deskewed)\n",
    "num_errors = np.sum(y_pred != y_test)\n",
    "\n",
    "# 3. Presentera resultatet\n",
    "print(\"=\"*30)\n",
    "print(f\"BASELINE SVC RESULTAT\")\n",
    "print(\"-\"*30)\n",
    "print(f\"Accuracy:  {baseline_acc:.5f}\")\n",
    "print(f\"Antal fel: {num_errors} av {len(y_test)}\")\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f100ebc",
   "metadata": {},
   "source": [
    "Dumpa ned modellen för voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56cfb7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- CELL 12: EXPORTERA MASTER-SVC TILL C-DISKEN ---\\nimport os\\n\\n# 1. Definiera den exakta sökvägen till din snabba disk\\n# Vi använder forward slashes (/) eller dubbla backslashes (\\\\) för Windows-sökvägar i Python\\nmodel_path = \\'C:/mnist_data/mnist_svc_hog_max.joblib\\'\\n\\n# 2. Säkerställ att mappen finns (ifall den raderats av misstag)\\nif not os.path.exists(\\'C:/mnist_data\\'):\\n    os.makedirs(\\'C:/mnist_data\\')\\n    print(\">>> Skapade mappen C:/mnist_data\")\\n\\n# 3. Spara modellen (skriver över den gamla filen automatiskt)\\nprint(f\"Sparar din boostade SVC-expert till {model_path}...\")\\njoblib.dump(final_pipe_ultra, model_path)\\n\\nprint(\"-\" * 40)\\nprint(\"KLART! Din starkaste SVC-modell hittills är nu säkrad på C-disken.\")\\nprint(\"Den är redo att agera \\'ordförande\\' i din ensemble-jury.\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- CELL 12: EXPORTERA MASTER-SVC TILL C-DISKEN ---\n",
    "import os\n",
    "\n",
    "# 1. Definiera den exakta sökvägen till din snabba disk\n",
    "# Vi använder forward slashes (/) eller dubbla backslashes (\\\\) för Windows-sökvägar i Python\n",
    "model_path = 'C:/mnist_data/mnist_svc_hog_max.joblib'\n",
    "\n",
    "# 2. Säkerställ att mappen finns (ifall den raderats av misstag)\n",
    "if not os.path.exists('C:/mnist_data'):\n",
    "    os.makedirs('C:/mnist_data')\n",
    "    print(\">>> Skapade mappen C:/mnist_data\")\n",
    "\n",
    "# 3. Spara modellen (skriver över den gamla filen automatiskt)\n",
    "print(f\"Sparar din boostade SVC-expert till {model_path}...\")\n",
    "joblib.dump(final_pipe_ultra, model_path)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"KLART! Din starkaste SVC-modell hittills är nu säkrad på C-disken.\")\n",
    "print(\"Den är redo att agera 'ordförande' i din ensemble-jury.\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
